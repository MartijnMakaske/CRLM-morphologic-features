{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAIRO5 data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from monai.transforms import (\n",
    "    Resize,\n",
    "    ScaleIntensityRange,\n",
    "    Compose\n",
    ")\n",
    "import shutil\n",
    "\n",
    "from scipy.ndimage import binary_dilation\n",
    "from scipy.ndimage import generate_binary_structure\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set numpy print options to avoid truncation\n",
    "#np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (CAIRO5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scans_orig_path = None\n",
    "all_scans_path = None\n",
    "\n",
    "for scan in os.listdir(all_scans_orig_path):\n",
    "        print(\"Currently processing: \", scan)\n",
    "        dest_name = scan.replace(\"_0000\", \"\")\n",
    "        #shutil.copy(os.path.join(all_scans_orig_path, scan), os.path.join(all_scans_path, dest_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define all useful paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All paths \n",
    "all_scans_path = None\n",
    "all_segmentations_path = None\n",
    "\n",
    "teacher_data_path = None\n",
    "\n",
    "paired_scans_path = None\n",
    "paired_segmentations_path = None\n",
    "\n",
    "# Clinical data file\n",
    "clinical_data_path = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete scans that are in teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Deletes scans from all_scans that are also in teacher_data\n",
    "\"\"\"\n",
    "\n",
    "# Get the list of scans in test_data and teacher_data\n",
    "teacher_data_scans = set(os.listdir(teacher_data_path))\n",
    "num_of_deleted = 0\n",
    "\n",
    "# Iterate through all scans in all_scans_path\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    # Check if the scan exists in either test_data or teacher_data\n",
    "    if scan in teacher_data_scans:\n",
    "        # Delete the scan from all_scans_path\n",
    "        os.remove(os.path.join(all_scans_path, scan))\n",
    "        print(f\"Deleted scan: {scan}\")\n",
    "        num_of_deleted += 1\n",
    "\n",
    "print(f\"Number of deleted scans: {num_of_deleted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all scans where scan_type =>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    scan_type = scan.split(\"_\")[1][0]\n",
    "    if int(scan_type) >= 2:\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))\n",
    "\n",
    "segmentations_to_delete = []\n",
    "\n",
    "for segm in os.listdir(all_segmentations_path):\n",
    "    segm_type = segm.split(\"_\")[1][0]\n",
    "    if int(segm_type) >= 2:\n",
    "        segmentations_to_delete.append(segm)\n",
    "\n",
    "\n",
    "for segm in segmentations_to_delete:\n",
    "    print(f\"Deleting segmentation: {segm}\")\n",
    "    os.remove(os.path.join(all_segmentations_path, segm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete scans without corresponding segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    if scan not in os.listdir(all_segmentations_path):\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 0 & 1 scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only scans where both 0 and 1 scan are present\n",
    "scans_in_folder = set(os.listdir(all_scans_path))\n",
    "scan_ids = set(scan.split(\"_\")[0] for scan in scans_in_folder)\n",
    "\n",
    "scans_to_keep = set()\n",
    "for scan_id in scan_ids:\n",
    "    scan_0 = f\"{scan_id}_0.nii.gz\"\n",
    "    scan_1 = f\"{scan_id}_1.nii.gz\"\n",
    "    if scan_0 in scans_in_folder and scan_1 in scans_in_folder:\n",
    "        scans_to_keep.add(scan_0)\n",
    "        scans_to_keep.add(scan_1)\n",
    "\n",
    "counter = 0\n",
    "for scan in scans_in_folder:\n",
    "    if scan not in scans_to_keep:\n",
    "        print(f\"Deleting scan: {scan}\")\n",
    "        counter += 1\n",
    "        os.remove(os.path.join(all_scans_path, scan))\n",
    "\n",
    "print(f\"Number of scans deleted: {counter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete scans of patients that are not in clinical file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = pd.read_excel(clinical_data_path)\n",
    "subject_keys = clinical_data[\"SubjectKey\"].astype(int).tolist()\n",
    "\n",
    "\n",
    "scans_to_delete = []\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    scan_id = scan.split(\"_\")[0][-3:]\n",
    "    if int(scan_id) not in subject_keys:\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment liver and bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Segments the liver and applies a bounding box \n",
    "\"\"\"\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    if scan in os.listdir(paired_scans_path):\n",
    "        print(f\"skipping: {scan}, since it already exists\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"currently processing: {scan}\")\n",
    "        \n",
    "        #load image and corresponding segmentation\n",
    "        image = nib.load(os.path.join(all_scans_path, scan))\n",
    "        segmentation = nib.load(os.path.join(all_segmentations_path, scan))\n",
    "\n",
    "        image_data = image.get_fdata()\n",
    "        segmentation_data = segmentation.get_fdata()\n",
    "\n",
    "        liver_mask = (segmentation_data == 12) | (segmentation_data == 13)\n",
    "\n",
    "        #apply mask to image\n",
    "        liver_image = np.copy(image_data)\n",
    "        liver_image[~liver_mask] = -1000\n",
    "\n",
    "        # Find the indices of the liver mask\n",
    "        mask_indices = np.argwhere(liver_mask)\n",
    "\n",
    "        # Calculate the bounding box\n",
    "        min_indices = mask_indices.min(axis=0)\n",
    "        max_indices = mask_indices.max(axis=0)\n",
    "\n",
    "        # Crop the liver image using the bounding box\n",
    "        cropped_liver_image = liver_image[min_indices[0]:max_indices[0]+1, min_indices[1]:max_indices[1]+1, min_indices[2]:max_indices[2]+1]\n",
    "\n",
    "        # Create a new NIfTI image\n",
    "        new_image = nib.Nifti1Image(cropped_liver_image, affine=image.affine, header=image.header)\n",
    "\n",
    "        # Save the new NIfTI image to a file with the original name\n",
    "        output_file_path = os.path.join(paired_scans_path, scan)\n",
    "        nib.save(new_image, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down-sized tumor mask data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 3D spherical-like connectivity structure\n",
    "structure = generate_binary_structure(3, 1)  # 3D, with connectivity=1\n",
    "\n",
    "for scan in os.listdir(paired_scans_path):\n",
    "    if scan in os.listdir(paired_segmentations_path):\n",
    "        #DOESNT WORK WITH .npy files\n",
    "        print(f\"skipping: {scan}, since it already exists\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Currently processing: {scan}\")\n",
    "        segmentation = nib.load(os.path.join(all_segmentations_path, scan))\n",
    "        segmentation_data = segmentation.get_fdata()\n",
    "\n",
    "        # Create a liver mask (labels 12 and 13)\n",
    "        liver_mask = (segmentation_data == 12) | (segmentation_data == 13)\n",
    "\n",
    "        # Find the indices of the liver mask\n",
    "        mask_indices = np.argwhere(liver_mask)\n",
    "\n",
    "        # Calculate the bounding box for the liver\n",
    "        min_indices = mask_indices.min(axis=0)\n",
    "        max_indices = mask_indices.max(axis=0)\n",
    "\n",
    "        # Crop the segmentation data using the bounding box\n",
    "        cropped_segmentation_data = segmentation_data[min_indices[0]:max_indices[0]+1, min_indices[1]:max_indices[1]+1, min_indices[2]:max_indices[2]+1]\n",
    "\n",
    "        # Create a tumor mask (label 13) within the cropped liver region\n",
    "        tumor_mask = (cropped_segmentation_data == 13)\n",
    "\n",
    "        # Apply binary dilation to the tumor mask\n",
    "        dilated_tumor_mask = binary_dilation(tumor_mask, structure=structure, iterations=8)    \n",
    "        dilated_tumor_mask = torch.tensor(dilated_tumor_mask).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "        # Downsize the dilated tumor mask\n",
    "        downsampled_tumor_mask = F.interpolate(dilated_tumor_mask, size=(128, 128, 32), mode=\"trilinear\", align_corners=False)\n",
    "        downsampled_tumor_mask = downsampled_tumor_mask.squeeze().numpy() \n",
    "\n",
    "        # Save the new NIfTI image\n",
    "        output_file_path = os.path.join(paired_segmentations_path, scan[:-7] + \".npy\")\n",
    "        np.save(output_file_path, downsampled_tumor_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are in paired_scans but not in all_scans_path\n",
    "paired_scans = set(os.listdir(paired_scans_path))\n",
    "all_scans = set(os.listdir(all_scans_path))\n",
    "scans_not_in_all_scans = paired_scans - all_scans\n",
    "print(\"Scans in paired_scans but not in all_scans_path:\")\n",
    "for scan in scans_not_in_all_scans:\n",
    "    print(scan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (CAIRO5 subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefull paths\n",
    " \n",
    "all_scans_path = None\n",
    "all_segmentations_path = None\n",
    "\n",
    "test_data_path = None\n",
    "\n",
    "paired_scans_path = None\n",
    "paired_segmentations_path = None\n",
    "\n",
    "resized_paired_scans_path = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy to correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan in os.listdir(test_data_path):\n",
    "    if scan.endswith(\".nii.gz\"):\n",
    "        if scan.endswith(\"_0000.nii.gz\"):\n",
    "            shutil.copy(os.path.join(test_data_path, scan), os.path.join(all_scans_path, scan.replace(\"_0000\", \"\")))\n",
    "        else: \n",
    "            shutil.copy(os.path.join(test_data_path, scan), os.path.join(all_segmentations_path, scan))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all scans and segmentations types >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    scan_type = scan.split(\"_\")[1][0]\n",
    "    if int(scan_type) >= 2:\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))\n",
    "\n",
    "segmentations_to_delete = []\n",
    "\n",
    "for segm in os.listdir(all_segmentations_path):\n",
    "    segm_type = segm.split(\"_\")[1][0]\n",
    "    if int(segm_type) >= 2:\n",
    "        segmentations_to_delete.append(segm)\n",
    "\n",
    "\n",
    "for segm in segmentations_to_delete:\n",
    "    print(f\"Deleting segmentation: {segm}\")\n",
    "    os.remove(os.path.join(all_segmentations_path, segm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete scans without corresponding segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    if scan not in os.listdir(all_segmentations_path):\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 0 & 1 scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    scan_type = scan.split(\"_\")[1][0]\n",
    "    if int(scan_type) == 0:\n",
    "        second_scan_name = scan.split(\"_\")[0] + \"_1.nii.gz\"\n",
    "        if second_scan_name not in os.listdir(all_scans_path):\n",
    "            scans_to_delete.append(scan)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and write every file to resolve corrupted segmentations issue\n",
    "Some segmentations are corrupted and not recognized as .nii.gz files. Opening and rewriting them with SimpleITK resolves this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk \n",
    "\n",
    "for segm in os.listdir(all_segmentations_path):\n",
    "    print(f\"Currently processing: {segm}\")\n",
    "    sitk_img = sitk.ReadImage(os.path.join(all_segmentations_path, segm))  # load with sitk\n",
    "    sitk.WriteImage(sitk_img, os.path.join(all_segmentations_path, segm))  # overwrite\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the gzip files are valid\n",
    "import gzip\n",
    "\n",
    "for filename in os.listdir(all_segmentations_path):\n",
    "    try:\n",
    "        with gzip.open(os.path.join(all_segmentations_path, filename), \"rb\") as f:\n",
    "            f.read(10)\n",
    "        print(\"Valid gzip\")\n",
    "    except Exception as e:\n",
    "        print(filename)\n",
    "        print(f\"Invalid gzip file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment liver and apply bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Segments the liver and applies a bounding box \n",
    "\"\"\"\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    if scan in os.listdir(paired_scans_path):\n",
    "        print(f\"skipping: {scan}, since it already exists\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"currently processing: {scan}\")\n",
    "        \n",
    "        #load image and corresponding segmentation\n",
    "        image = nib.load(os.path.join(all_scans_path, scan))\n",
    "        segmentation = nib.load(os.path.join(all_segmentations_path, scan))\n",
    "\n",
    "        image_data = image.get_fdata()\n",
    "        segmentation_data = segmentation.get_fdata()\n",
    "\n",
    "        liver_mask = (segmentation_data == 12) | (segmentation_data == 13)\n",
    "\n",
    "        #apply mask to image\n",
    "        liver_image = np.copy(image_data)\n",
    "        liver_image[~liver_mask] = -1000\n",
    "\n",
    "        # Find the indices of the liver mask\n",
    "        mask_indices = np.argwhere(liver_mask)\n",
    "\n",
    "        # Calculate the bounding box\n",
    "        min_indices = mask_indices.min(axis=0)\n",
    "        max_indices = mask_indices.max(axis=0)\n",
    "\n",
    "        # Crop the liver image using the bounding box\n",
    "        cropped_liver_image = liver_image[min_indices[0]:max_indices[0]+1, min_indices[1]:max_indices[1]+1, min_indices[2]:max_indices[2]+1]\n",
    "\n",
    "        # Create a new NIfTI image\n",
    "        new_image = nib.Nifti1Image(cropped_liver_image, affine=image.affine, header=image.header)\n",
    "\n",
    "        # Save the new NIfTI image to a file with the original name\n",
    "        output_file_path = os.path.join(paired_scans_path, scan)\n",
    "        nib.save(new_image, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation downsizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 3D spherical-like connectivity structure\n",
    "structure = generate_binary_structure(3, 1)  # 3D, with connectivity=1\n",
    "\n",
    "for scan in os.listdir(paired_scans_path):\n",
    "    print(f\"Currently processing: {scan}\")\n",
    "    segmentation = nib.load(os.path.join(all_segmentations_path, scan))\n",
    "    segmentation_data = segmentation.get_fdata()\n",
    "\n",
    "    # Create a liver mask (labels 12 and 13)\n",
    "    liver_mask = (segmentation_data == 12) | (segmentation_data == 13)\n",
    "\n",
    "    # Find the indices of the liver mask\n",
    "    mask_indices = np.argwhere(liver_mask)\n",
    "\n",
    "\n",
    "    # Calculate the bounding box for the liver\n",
    "    min_indices = mask_indices.min(axis=0)\n",
    "    max_indices = mask_indices.max(axis=0)\n",
    "\n",
    "    # Crop the segmentation data using the bounding box\n",
    "    cropped_segmentation_data = segmentation_data[min_indices[0]:max_indices[0]+1, min_indices[1]:max_indices[1]+1, min_indices[2]:max_indices[2]+1]\n",
    "\n",
    "    # Create a tumor mask (label 13) within the cropped liver region\n",
    "    tumor_mask = (cropped_segmentation_data == 13)\n",
    "\n",
    "    # Apply binary dilation to the tumor mask\n",
    "    dilated_tumor_mask = binary_dilation(tumor_mask, structure=structure, iterations=8)\n",
    "    dilated_tumor_mask = torch.tensor(dilated_tumor_mask).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "\n",
    "    # Downsize the dilated tumor mask\n",
    "    downsampled_tumor_mask = F.interpolate(dilated_tumor_mask, size=(128, 128, 32), mode=\"trilinear\", align_corners=False)\n",
    "    downsampled_tumor_mask = downsampled_tumor_mask.squeeze().numpy() \n",
    "\n",
    "    # Create a new NIfTI image for the downsampled tumor mask\n",
    "    #new_image = nib.Nifti1Image(dilated_tumor_mask.astype(np.uint8), affine=segmentation.affine, header=segmentation.header)\n",
    "\n",
    "    # Save the new NIfTI image\n",
    "    output_file_path = os.path.join(paired_segmentations_path, scan[:-7] + \".npy\")\n",
    "    np.save(output_file_path, downsampled_tumor_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan resizing\n",
    "These scans are used to overlay with the saliency maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_scans_path = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan in os.listdir(resize_scans_path):\n",
    "    print(f\"Currently processing: {scan}\")\n",
    "    image = nib.load(os.path.join(resize_scans_path, scan))\n",
    "    image_data = image.get_fdata()\n",
    "\n",
    "    # Add channel dimension to image data\n",
    "    image_data = np.expand_dims(image_data, axis=0)\n",
    "\n",
    "    transform = [\n",
    "        ScaleIntensityRange(a_min=-100, a_max=200, b_min=0.0, b_max=1.0, clip=True),\n",
    "        Resize((256, 256, 64), mode=\"trilinear\")\n",
    "    ]\n",
    "    image_data = Compose(transform)(image_data)\n",
    "    image_data = image_data.squeeze()\n",
    "\n",
    "    nifti_image = nib.Nifti1Image(image_data, affine=image.affine, header= image.header)\n",
    "\n",
    "    nib.save(nifti_image, os.path.join(resize_scans_path, scan))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (AMCore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usefull paths\n",
    " \n",
    "all_scans_path = None\n",
    "all_segmentations_path = None\n",
    "\n",
    "test_data_path = None\n",
    "paired_scans_path = None\n",
    "paired_segmentations_path = None\n",
    "\n",
    "resized_paired_scans_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy to correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan in os.listdir(test_data_path):\n",
    "    if scan.endswith(\".nii.gz\"):\n",
    "        if scan.endswith(\"_0000.nii.gz\"):\n",
    "            shutil.copy(os.path.join(test_data_path, scan), os.path.join(all_scans_path, scan.replace(\"_0000\", \"\")))\n",
    "        else: \n",
    "            shutil.copy(os.path.join(test_data_path, scan), os.path.join(all_segmentations_path, scan))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Delete scans =>2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    scan_type = scan.split(\"_\")[1][0]\n",
    "    if int(scan_type) >= 2:\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))\n",
    "\n",
    "segmentations_to_delete = []\n",
    "\n",
    "for segm in os.listdir(all_segmentations_path):\n",
    "    segm_type = segm.split(\"_\")[1][0]\n",
    "    if int(segm_type) >= 2:\n",
    "        segmentations_to_delete.append(segm)\n",
    "\n",
    "\n",
    "for segm in segmentations_to_delete:\n",
    "    print(f\"Deleting segmentation: {segm}\")\n",
    "    os.remove(os.path.join(all_segmentations_path, segm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete scans without segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    if scan not in os.listdir(all_segmentations_path):\n",
    "        scans_to_delete.append(scan)\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset paired scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_to_delete = []\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    scan_type = scan.split(\"_\")[1][0]\n",
    "    if int(scan_type) == 0:\n",
    "        second_scan_name = scan.split(\"_\")[0] + \"_1.nii.gz\"\n",
    "        if second_scan_name not in os.listdir(all_scans_path):\n",
    "            scans_to_delete.append(scan)\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for scan in scans_to_delete:\n",
    "    print(f\"Deleting scan: {scan}\")\n",
    "    os.remove(os.path.join(all_scans_path, scan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment liver and apply bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Segments the liver and applies a bounding box \n",
    "\"\"\"\n",
    "\n",
    "for scan in os.listdir(all_scans_path):\n",
    "    if scan in os.listdir(paired_scans_path):\n",
    "        print(f\"skipping: {scan}, since it already exists\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"currently processing: {scan}\")\n",
    "        \n",
    "        #load image and corresponding segmentation\n",
    "        image = nib.load(os.path.join(all_scans_path, scan))\n",
    "        segmentation = nib.load(os.path.join(all_segmentations_path, scan))\n",
    "\n",
    "        image_data = image.get_fdata()\n",
    "        segmentation_data = segmentation.get_fdata()\n",
    "\n",
    "        liver_mask = (segmentation_data == 12) | (segmentation_data == 13)\n",
    "\n",
    "        #apply mask to image\n",
    "        liver_image = np.copy(image_data)\n",
    "        liver_image[~liver_mask] = -1000\n",
    "\n",
    "        # Find the indices of the liver mask\n",
    "        mask_indices = np.argwhere(liver_mask)\n",
    "\n",
    "        # Calculate the bounding box\n",
    "        min_indices = mask_indices.min(axis=0)\n",
    "        max_indices = mask_indices.max(axis=0)\n",
    "\n",
    "        # Crop the liver image using the bounding box\n",
    "        cropped_liver_image = liver_image[min_indices[0]:max_indices[0]+1, min_indices[1]:max_indices[1]+1, min_indices[2]:max_indices[2]+1]\n",
    "\n",
    "        # Create a new NIfTI image\n",
    "        new_image = nib.Nifti1Image(cropped_liver_image, affine=image.affine, header=image.header)\n",
    "\n",
    "        # Save the new NIfTI image to a file with the original name\n",
    "        output_file_path = os.path.join(paired_scans_path, scan)\n",
    "        nib.save(new_image, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 3D spherical-like connectivity structure\n",
    "structure = generate_binary_structure(3, 1)  # 3D, with connectivity=1\n",
    "\n",
    "for scan in os.listdir(paired_scans_path):\n",
    "    print(f\"Currently processing: {scan}\")\n",
    "    segmentation = nib.load(os.path.join(all_segmentations_path, scan))\n",
    "    segmentation_data = segmentation.get_fdata()\n",
    "\n",
    "    # Create a liver mask (labels 12 and 13)\n",
    "    liver_mask = (segmentation_data == 12) | (segmentation_data == 13)\n",
    "\n",
    "    # Find the indices of the liver mask\n",
    "    mask_indices = np.argwhere(liver_mask)\n",
    "\n",
    "\n",
    "    # Calculate the bounding box for the liver\n",
    "    min_indices = mask_indices.min(axis=0)\n",
    "    max_indices = mask_indices.max(axis=0)\n",
    "\n",
    "    # Crop the segmentation data using the bounding box\n",
    "    cropped_segmentation_data = segmentation_data[min_indices[0]:max_indices[0]+1, min_indices[1]:max_indices[1]+1, min_indices[2]:max_indices[2]+1]\n",
    "\n",
    "    # Create a tumor mask (label 13) within the cropped liver region\n",
    "    tumor_mask = (cropped_segmentation_data == 13)\n",
    "\n",
    "    # Apply binary dilation to the tumor mask\n",
    "    dilated_tumor_mask = binary_dilation(tumor_mask, structure=structure, iterations=8)\n",
    "    dilated_tumor_mask = torch.tensor(dilated_tumor_mask).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "\n",
    "    # Downsize the dilated tumor mask\n",
    "    downsampled_tumor_mask = F.interpolate(dilated_tumor_mask, size=(128, 128, 32), mode=\"trilinear\", align_corners=False)\n",
    "    downsampled_tumor_mask = downsampled_tumor_mask.squeeze().numpy() \n",
    "\n",
    "    # Create a new NIfTI image for the downsampled tumor mask\n",
    "    #new_image = nib.Nifti1Image(dilated_tumor_mask.astype(np.uint8), affine=segmentation.affine, header=segmentation.header)\n",
    "\n",
    "    # Save the new NIfTI image\n",
    "    output_file_path = os.path.join(paired_segmentations_path, scan[:-7] + \".npy\")\n",
    "    np.save(output_file_path, downsampled_tumor_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the average dimension of all scans in paired_scans_path\n",
    "\n",
    "dims = []\n",
    "for scan_file in os.listdir(paired_scans_path):\n",
    "    img = nib.load(os.path.join(paired_scans_path, scan_file))\n",
    "    dims.append(img.shape)\n",
    "\n",
    "dims = np.array(dims)\n",
    "avg_dims = np.mean(dims, axis=0)\n",
    "\n",
    "plt.bar(['X', 'Y', 'Z'], avg_dims)\n",
    "plt.ylabel('Average size')\n",
    "plt.title('Average dimension of scans in paired_scans')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
